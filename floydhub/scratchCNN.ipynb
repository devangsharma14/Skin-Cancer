{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "\n",
    "batch_size=20\n",
    "num_workers=0\n",
    "\n",
    "data_dir='/floyd/input/kaggle_skin_cancer/'\n",
    "train_dir=os.path.join(data_dir, 'train/')\n",
    "valid_dir=os.path.join(data_dir, 'valid/')\n",
    "\n",
    "train_data_transform=transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_data_transform=transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_data=datasets.ImageFolder(train_dir, transform=train_data_transform)\n",
    "valid_data=datasets.ImageFolder(valid_dir, transform=test_data_transform)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(train_data,\n",
    "                                         batch_size=batch_size,\n",
    "                                         num_workers=num_workers,\n",
    "                                         shuffle=True)\n",
    "valid_loader=torch.utils.data.DataLoader(valid_data,\n",
    "                                         batch_size=batch_size,\n",
    "                                         num_workers=num_workers, \n",
    "                                         shuffle=True)\n",
    "\n",
    "loaders_scratch={\n",
    "    \"train\": train_loader,\n",
    "    \"valid\": valid_loader,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=50176, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1=nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2=nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3=nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool=nn.MaxPool2d(2,2)\n",
    "        self.fc1=nn.Linear(64*28*28, 500)\n",
    "        self.fc2=nn.Linear(500, 2)\n",
    "        self.dropout=nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=self.pool(F.relu(self.conv3(x)))\n",
    "        x=x.view(-1,64*28*28)\n",
    "        x=self.dropout(x)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=self.dropout(x)\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model_scratch = Net()\n",
    "print(model_scratch)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model_scratch.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion_scratch = nn.CrossEntropyLoss()\n",
    "optimizer_scratch = optim.SGD(model_scratch.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output=model(data)\n",
    "            loss=criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            \n",
    "            if batch_idx % 100 == 99:\n",
    "                print('Epoch %d, Batch %d loss: %.6f' %\n",
    "                  (epoch, batch_idx + 1, train_loss))\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            output=model(data)\n",
    "            loss=criterion(output, target)\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    " \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        if valid_loss < valid_loss_min:\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100 loss: 0.605328\n",
      "Epoch: 1 \tTraining Loss: 0.594873 \tValidation Loss: 0.463266\n",
      "Validation loss decreased (inf --> 0.463266).  Saving model ...\n",
      "Epoch 2, Batch 100 loss: 0.532838\n",
      "Epoch: 2 \tTraining Loss: 0.525955 \tValidation Loss: 0.463167\n",
      "Validation loss decreased (0.463266 --> 0.463167).  Saving model ...\n",
      "Epoch 3, Batch 100 loss: 0.507710\n",
      "Epoch: 3 \tTraining Loss: 0.497764 \tValidation Loss: 0.429014\n",
      "Validation loss decreased (0.463167 --> 0.429014).  Saving model ...\n",
      "Epoch 4, Batch 100 loss: 0.429237\n",
      "Epoch: 4 \tTraining Loss: 0.444384 \tValidation Loss: 0.419116\n",
      "Validation loss decreased (0.429014 --> 0.419116).  Saving model ...\n",
      "Epoch 5, Batch 100 loss: 0.433814\n",
      "Epoch: 5 \tTraining Loss: 0.439973 \tValidation Loss: 0.404448\n",
      "Validation loss decreased (0.419116 --> 0.404448).  Saving model ...\n",
      "Epoch 6, Batch 100 loss: 0.441325\n",
      "Epoch: 6 \tTraining Loss: 0.440385 \tValidation Loss: 0.416013\n",
      "Epoch 7, Batch 100 loss: 0.427040\n",
      "Epoch: 7 \tTraining Loss: 0.424853 \tValidation Loss: 0.389681\n",
      "Validation loss decreased (0.404448 --> 0.389681).  Saving model ...\n",
      "Epoch 8, Batch 100 loss: 0.434960\n",
      "Epoch: 8 \tTraining Loss: 0.429336 \tValidation Loss: 0.392909\n",
      "Epoch 9, Batch 100 loss: 0.416289\n",
      "Epoch: 9 \tTraining Loss: 0.411982 \tValidation Loss: 0.388870\n",
      "Validation loss decreased (0.389681 --> 0.388870).  Saving model ...\n",
      "Epoch 10, Batch 100 loss: 0.414596\n",
      "Epoch: 10 \tTraining Loss: 0.417557 \tValidation Loss: 0.389326\n",
      "Epoch 11, Batch 100 loss: 0.400272\n",
      "Epoch: 11 \tTraining Loss: 0.408068 \tValidation Loss: 0.376921\n",
      "Validation loss decreased (0.388870 --> 0.376921).  Saving model ...\n",
      "Epoch 12, Batch 100 loss: 0.401265\n",
      "Epoch: 12 \tTraining Loss: 0.407461 \tValidation Loss: 0.451560\n",
      "Epoch 13, Batch 100 loss: 0.408206\n",
      "Epoch: 13 \tTraining Loss: 0.412436 \tValidation Loss: 0.376801\n",
      "Validation loss decreased (0.376921 --> 0.376801).  Saving model ...\n",
      "Epoch 14, Batch 100 loss: 0.408762\n",
      "Epoch: 14 \tTraining Loss: 0.405232 \tValidation Loss: 0.381541\n",
      "Epoch 15, Batch 100 loss: 0.395965\n",
      "Epoch: 15 \tTraining Loss: 0.403439 \tValidation Loss: 0.387069\n",
      "Epoch 16, Batch 100 loss: 0.394176\n",
      "Epoch: 16 \tTraining Loss: 0.397210 \tValidation Loss: 0.360620\n",
      "Validation loss decreased (0.376801 --> 0.360620).  Saving model ...\n",
      "Epoch 17, Batch 100 loss: 0.389761\n",
      "Epoch: 17 \tTraining Loss: 0.390269 \tValidation Loss: 0.366666\n",
      "Epoch 18, Batch 100 loss: 0.391942\n",
      "Epoch: 18 \tTraining Loss: 0.390382 \tValidation Loss: 0.385286\n",
      "Epoch 19, Batch 100 loss: 0.388758\n",
      "Epoch: 19 \tTraining Loss: 0.382234 \tValidation Loss: 0.393965\n",
      "Epoch 20, Batch 100 loss: 0.392363\n",
      "Epoch: 20 \tTraining Loss: 0.390265 \tValidation Loss: 0.349995\n",
      "Validation loss decreased (0.360620 --> 0.349995).  Saving model ...\n",
      "Epoch 21, Batch 100 loss: 0.388240\n",
      "Epoch: 21 \tTraining Loss: 0.378379 \tValidation Loss: 0.377233\n",
      "Epoch 22, Batch 100 loss: 0.380113\n",
      "Epoch: 22 \tTraining Loss: 0.379593 \tValidation Loss: 0.427592\n",
      "Epoch 23, Batch 100 loss: 0.372706\n",
      "Epoch: 23 \tTraining Loss: 0.375550 \tValidation Loss: 0.352844\n",
      "Epoch 24, Batch 100 loss: 0.385900\n",
      "Epoch: 24 \tTraining Loss: 0.381894 \tValidation Loss: 0.375718\n",
      "Epoch 25, Batch 100 loss: 0.362800\n",
      "Epoch: 25 \tTraining Loss: 0.374089 \tValidation Loss: 0.357512\n",
      "Epoch 26, Batch 100 loss: 0.376031\n",
      "Epoch: 26 \tTraining Loss: 0.372214 \tValidation Loss: 0.344110\n",
      "Validation loss decreased (0.349995 --> 0.344110).  Saving model ...\n",
      "Epoch 27, Batch 100 loss: 0.369109\n",
      "Epoch: 27 \tTraining Loss: 0.371526 \tValidation Loss: 0.355109\n",
      "Epoch 28, Batch 100 loss: 0.381975\n",
      "Epoch: 28 \tTraining Loss: 0.383747 \tValidation Loss: 0.348259\n",
      "Epoch 29, Batch 100 loss: 0.366790\n",
      "Epoch: 29 \tTraining Loss: 0.368582 \tValidation Loss: 0.365683\n",
      "Epoch 30, Batch 100 loss: 0.371292\n",
      "Epoch: 30 \tTraining Loss: 0.374696 \tValidation Loss: 0.355790\n"
     ]
    }
   ],
   "source": [
    "model_scratch = train(30, loaders_scratch, model_scratch, optimizer_scratch, criterion_scratch, use_cuda, 'model_scratch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scratch.load_state_dict(torch.load('model_scratch.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8455, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "running_corrects = 0\n",
    "for batch_idx, (data, target) in enumerate(loaders_scratch['valid']):\n",
    "    if use_cuda:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    outputs=model_scratch(data)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    running_corrects += torch.sum(preds == target.data)\n",
    "acc = running_corrects.double() / len(loaders_scratch['valid'].dataset)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
